{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHkmkekm2yk8KP4mwp4mDE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AleAguirreM/Analitica3AA/blob/main/e_despliegue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVvABiPkTZyH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sqlite3 as sql\n",
        "import a_funciones as fn ## para procesamiento\n",
        "import openpyxl\n",
        "####Paquete para sistema basado en contenido ####\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocesar():\n",
        "\n",
        "    #### conectar_base_de_Datos#################\n",
        "    conn=sql.connect('C:\\\\cod\\\\LEA3_RecSys\\\\data\\\\db_books2')\n",
        "    cur=conn.cursor()\n",
        "\n",
        "\n",
        "    ######## convertir datos crudos a bases filtradas por usuarios que tengan cierto número de calificaciones\n",
        "    fn.ejecutar_sql('C:\\\\cod\\\\LEA3_RecSys\\\\preprocesamientos.sql', cur)\n",
        "\n",
        "    ##### llevar datos que cambian constantemente a python ######\n",
        "    books=pd.read_sql('select * from books_final', conn )\n",
        "    ratings=pd.read_sql('select * from ratings_final', conn)\n",
        "    usuarios=pd.read_sql('select distinct (user_id) as user_id from ratings_final',conn)\n",
        "\n",
        "\n",
        "    #### transformación de datos crudos - Preprocesamiento ################\n",
        "    books['year_pub']=books.year_pub.astype('int')\n",
        "\n",
        "    ##### escalar para que año esté en el mismo rango ###\n",
        "    sc=MinMaxScaler()\n",
        "    books[[\"year_sc\"]]=sc.fit_transform(books[['year_pub']])\n",
        "\n",
        "    ## eliminar filas que no se van a utilizar ###\n",
        "    books_dum1=books.drop(columns=['isbn','i_url','year_pub','book_title'])\n",
        "\n",
        "    col_dum=['book_author','publisher']\n",
        "    books_dum2=pd.get_dummies(books_dum1,columns=col_dum)\n",
        "    return books_dum2,books, conn, cur"
      ],
      "metadata": {
        "id": "7IHWFfPcTjBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################################\n",
        "###############Función para entrenar modelo por cada usuario ##########\n",
        "###############Basado en contenido todo lo visto por el usuario Knn#############################\n",
        "def recomendar(user_id):\n",
        "\n",
        "    books_dum2, books, conn, cur= preprocesar()\n",
        "\n",
        "    ratings=pd.read_sql('select *from ratings_final where user_id=:user',conn, params={'user':user_id})\n",
        "    l_books_r=ratings['isbn'].to_numpy()\n",
        "    books_dum2[['isbn','book_title']]=books[['isbn','book_title']]\n",
        "    books_r=books_dum2[books_dum2['isbn'].isin(l_books_r)]\n",
        "    books_r=books_r.drop(columns=['isbn','book_title'])\n",
        "    books_r[\"indice\"]=1 ### para usar group by y que quede en formato pandas tabla de centroide\n",
        "    centroide=books_r.groupby(\"indice\").mean()\n",
        "\n",
        "\n",
        "    books_nr=books_dum2[~books_dum2['isbn'].isin(l_books_r)]\n",
        "    books_nr=books_nr.drop(columns=['isbn','book_title'])\n",
        "    model=neighbors.NearestNeighbors(n_neighbors=11, metric='cosine')\n",
        "    model.fit(books_nr)\n",
        "    dist, idlist = model.kneighbors(centroide)\n",
        "\n",
        "    ids=idlist[0]\n",
        "    recomend_b=books.loc[ids][['book_title','isbn']]\n",
        "\n",
        "\n",
        "    return recomend_b\n",
        "\n"
      ],
      "metadata": {
        "id": "0HNJZbiuTlnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Generar recomendaciones para usuario lista de usuarios ####\n",
        "##### No se hace para todos porque es muy pesado #############\n",
        "def main(list_user):\n",
        "\n",
        "    recomendaciones_todos=pd.DataFrame()\n",
        "    for user_id in list_user:\n",
        "\n",
        "        recomendaciones=recomendar(user_id)\n",
        "        recomendaciones[\"user_id\"]=user_id\n",
        "        recomendaciones.reset_index(inplace=True,drop=True)\n",
        "\n",
        "        recomendaciones_todos=pd.concat([recomendaciones_todos, recomendaciones])\n",
        "\n",
        "    recomendaciones_todos.to_excel('C:\\\\cod\\\\LEA3_RecSys\\\\salidas\\\\reco\\\\recomendaciones.xlsx')\n",
        "    recomendaciones_todos.to_csv('C:\\\\cod\\\\LEA3_RecSys\\\\salidas\\\\reco\\\\recomendaciones.csv')\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    list_user=[52853,31226,167471,8066 ]\n",
        "    main(list_user)\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.executable"
      ],
      "metadata": {
        "id": "nIndWU-vTodh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}